import gradio as gr
import json
import tempfile
from translatepy import Translator
from datetime import datetime
import os
import pandas as pd
import numpy as np
from collections import Counter
import warnings
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from scipy.stats import pearsonr, spearmanr
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import matplotlib.pyplot as plt
import seaborn as sns

# ×¡×ª×™××ª ××–×”×¨×•×ª
warnings.filterwarnings('ignore')

translator = Translator()

# ××™×œ×•×Ÿ ×ª×¨×’×•× ××œ×
translation_cache = {
    "××™×˜×™": "Slow",
    "×œ× ××¦×œ×™×— ×œ×”×ª××–×Ÿ ×•×œ×”×ª×××Ÿ": "Unable to balance and exercise",
    "×‘×•×§×¨ ×˜×•×‘": "Good morning",
    "×ª×—×•×©×” ×›×œ×œ×™×ª ×¤×—×•×ª ×˜×•×‘×”": "General feeling is less good",
    "××¨×’×™×© ××¦×•×™×Ÿ": "Feeling excellent",
    "××™×˜×™×•×ª": "Slowness",
    "×˜×•×‘": "Good",
    "×”×ª×›×•×•×¦×•×™×•×ª ×‘×›×¤×•×ª ×”×¨×’×œ×™×™× ×œ××©×š 15 ×“×§×•×ª": "Foot cramps for 15 minutes",
    "×”×ª×›×•×•×¦×•×™×•×ª ×‘××¦×‘×¢×•×ª ×¨×’×œ ×™××™×Ÿ": "Toe cramps in right foot",
    "××–×™×œ×§×˜": "Azilect",
    "×“×•×¤×™×§×¨": "Dopicar",
    "×“×•×¤×™×§×¨ 125": "Dopicar 125",
    "×“×•×¤×™×§×¨ 175": "Dopicar 175",
    "×“×•×¤×™×§×¨ 250": "Dopicar 250",
    "×§×¤×”": "Coffee",
    "×—×¦×™ ×¤×™×ª×” ×¢× ×—×××ª ×‘×•×˜× ×™×": "Half pita with peanut butter",
    "×¤×œ×¤×œ ×•××œ×¤×¤×•×Ÿ": "Pepper and cucumber",
    "×§×¢×¨×ª ×§×•×¨× ×¤×œ×§×¡ ×¢× ×—×œ×‘ ×¡×•×™×” ×•×¦×™××•×§×™×": "Bowl of cornflakes with soy milk and raisins",
    "×§×¢×¨×ª ×§×•×¨× ×¤×œ×§×¡ ×¢× ×—×œ×‘ ×©×§×“×™× ×•×¦×™××•×§×™×": "Bowl of cornflakes with almond milk and raisins",
    "×¡×œ××•×Ÿ ×¢× ×¤×™×¨×” ×•××¤×•× ×”": "Salmon with mashed potatoes and peas",
    "×¤×™×ª×” ×˜×—×™× ×” ××œ×¤×¤×•×Ÿ ×¢×’×‘× ×™×™×” ×•×©× ×™×¦×œ ×§×˜×Ÿ": "Pita with tahini, cucumber, tomato and small schnitzel",
    "××¢×“×Ÿ ×¡×•×™×” ××¤×¨×¡×§": "Peach soy pudding",
    "×¤×œ×¤×œ ×¢× ×§×•×˜×’'": "Pepper with cottage cheese",
    "×¨×‘×¢ ×¤×™×ª×” ×¢× ×××¨×— ×‘×•×˜× ×™×": "Quarter pita with peanut spread",
    "×ª×¤×•\"× ××‘×•×©×œ×™× ×©×¢×•×¢×™×ª ×™×¨×•×§×” ×•×§×¦×ª ×§×™× ×•××”, 50 ×’×¨× ×¢×•×£": "Boiled potatoes, green beans and a bit of quinoa with 50g chicken",
    "×ª×¤×•\"× ××‘×•×©×œ×™×, ×¡×œ×˜ ×‘×™×¦×™×": "Boiled potatoes and egg salad",
    "××¨×§ ×™×¨×§×•×ª ×¢× ×¤×ª×™×ª×™×": "Vegetable soup with ptitim",
    "××¨×§ ××¤×•× ×”, ×›×¨×•×‘×™×ª ××‘×•×©×œ×ª": "Pea soup with cooked cauliflower",
    "×¦×œ×—×ª ××¨×§ ×¡×œ×¨×™": "Plate of celery soup",
    "×¤××™ ××’×¡×™× ×•×§×¤×” ×§×˜×Ÿ": "Pear pie and small coffee",
    "×©×§×“×™× ×˜×‘×¢×™×™×": "Natural almonds",
    "×¢×•×’×ª ×ª×¤×•×—×™×": "Apple cake",
    "×—×œ×‘ ×¡×•×™×”": "Soy milk",
    "×—×œ×‘ ×©×§×“×™×": "Almond milk",
    "×¦×™××•×§×™×": "Raisins",
    "××œ×¤×¤×•×Ÿ": "Cucumber",
    "×¤×œ×¤×œ": "Pepper",
    "×˜×—×™× ×”": "Tahini",
    "×¢×’×‘× ×™×™×”": "Tomato",
    "×¤×™×¨×”": "Mashed potatoes",
    "××¤×•× ×”": "Peas",
    "×©× ×™×¦×œ": "Schnitzel",
    "×—×¦×™ ×¤×™×ª×” ×¢× ×¨×™×‘×”": "Half pita with jam",
    "×¨×™×‘×”": "Jam",
    "×¡×œ×˜ ×‘×™×¦×™×": "Egg salad",
    "×‘×™×¦×™×": "Eggs",
    "×§×•×˜×’'": "Cottage cheese",
    "×©×¢×•×¢×™×ª ×™×¨×•×§×”": "Green beans",
    "×§×™× ×•××”": "Quinoa",
    "×¢×•×£": "Chicken",
    "×¤×ª×™×ª×™×": "Ptitim",
    "×›×¨×•×‘×™×ª ××‘×•×©×œ×ª": "Cooked cauliflower",
    "×›×¨×•×‘×™×ª": "Cauliflower",
    "×ª×¤×•\"×": "Potatoes",
    "×ª×¤×•×—×™ ××“××”": "Potatoes",
    "××¦×‘ ×¤×¨×§×™× ×¡×•×Ÿ": "Parkinson's State",
    "××¦×‘ ×¤×™×–×™": "Physical State",
    "××¦×‘ ×”×¨×•×— ×©×œ×™": "My Mood",
    "×¡×™××¤×˜×•××™×": "symptoms",
    "×ª×¨×•×¤×•×ª": "medicines",
    "×ª×–×•× ×”": "nutritions",
    "×¤×¢×™×œ×•×™×•×ª": "activities",
    "×ª×¨×•×¤×”": "medicine",
    "×¤×¢×™×œ×•×ª": "activity",
    "×¤×™×œ": "Pill",
    "×›×“×•×¨": "Pill",
    "×’×‘×•×”": "High",
    "×‘×™× ×•× ×™": "Moderate",
    "× ××•×š": "Low",
    "×¨×¢×“": "Tremor",
    "×§×•×©×™ ×‘×“×™×‘×•×¨": "Speech Difficulty",
    "×§×©×™×—×•×ª": "Stiffness",
    "××™×˜×™×•×ª ×‘×ª× ×•×¢×”": "Slowness of Movement",
    "×‘×¢×™×•×ª ×©×™×•×•×™ ××©×§×œ": "Balance Problems",
    "×¢×™×™×¤×•×ª": "Fatigue",
    "×›××‘×™×": "Pain",
    "×”×œ×™×›×”": "Walking",
    "×¨×™×¦×”": "Running",
    "×©×—×™×™×”": "Swimming",
    "×™×•×’×”": "Yoga",
    "××™××•×Ÿ ×›×•×—": "Strength Training",
    "××™××•×Ÿ ×˜× ×©": "Tennis Training",
    "××™××•×Ÿ ×˜× ×© ×§×‘×•×¦×ª×™": "Group Tennis Training",
    "××©×¢×” 2020 3 ××©×—×§×™×. ×”×¤×¡×§×” ×©×œ 15 ×“×§×•×ª ×œ×¤× ×™ ×”××©×—×§×™×": "From 8:20 PM, 3 games. 15-minute break before the games",
    "×˜× ×©": "Tennis",
}

# ××™×œ×•×Ÿ ×¢×¨×›×™× ×ª×–×•× ×ª×™×™× ××•×¨×—×‘
nutrition_db = {
    "×¤×™×ª×”": {"proteins": 6, "fats": 1.5, "carbohydrates": 33, "dietaryFiber": 1.5},
    "×—×××ª ×‘×•×˜× ×™×": {"proteins": 8, "fats": 16, "carbohydrates": 6, "dietaryFiber": 2},
    "×××¨×— ×‘×•×˜× ×™×": {"proteins": 8, "fats": 16, "carbohydrates": 6, "dietaryFiber": 2},
    "×§×¤×”": {"proteins": 0.3, "fats": 0.1, "carbohydrates": 0.4, "dietaryFiber": 0},
    "×¡×œ××•×Ÿ": {"proteins": 25, "fats": 14, "carbohydrates": 0, "dietaryFiber": 0},
    "×§×•×¨× ×¤×œ×§×¡": {"proteins": 7, "fats": 1, "carbohydrates": 84, "dietaryFiber": 3},
    "×—×œ×‘ ×¡×•×™×”": {"proteins": 3.3, "fats": 2, "carbohydrates": 4, "dietaryFiber": 0.5},
    "×—×œ×‘ ×©×§×“×™×": {"proteins": 1.1, "fats": 2.5, "carbohydrates": 3, "dietaryFiber": 0.7},
    "×¦×™××•×§×™×": {"proteins": 0.5, "fats": 0.2, "carbohydrates": 17, "dietaryFiber": 0.8},
    "××œ×¤×¤×•×Ÿ": {"proteins": 0.7, "fats": 0.1, "carbohydrates": 2.5, "dietaryFiber": 0.5},
    "×¤×œ×¤×œ": {"proteins": 1, "fats": 0.3, "carbohydrates": 6, "dietaryFiber": 2.1},
    "×©× ×™×¦×œ": {"proteins": 18, "fats": 13, "carbohydrates": 8, "dietaryFiber": 0.5},
    "×˜×—×™× ×”": {"proteins": 17, "fats": 57, "carbohydrates": 10, "dietaryFiber": 10},
    "×¢×’×‘× ×™×™×”": {"proteins": 0.9, "fats": 0.2, "carbohydrates": 3.9, "dietaryFiber": 1.2},
    "×¤×™×¨×”": {"proteins": 2, "fats": 0.1, "carbohydrates": 15, "dietaryFiber": 1.5},
    "××¤×•× ×”": {"proteins": 5, "fats": 0.4, "carbohydrates": 14, "dietaryFiber": 5},
    "××¢×“×Ÿ ×¡×•×™×” ××¤×¨×¡×§": {"proteins": 4.4, "fats": 2.25, "carbohydrates": 24.5, "dietaryFiber": 3},
    "×©×§×“×™× ×˜×‘×¢×™×™×": {"proteins": 21, "fats": 49, "carbohydrates": 22, "dietaryFiber": 12.5},
    "×¤××™ ××’×¡×™× ×•×§×¤×” ×§×˜×Ÿ": {"proteins": 3.3, "fats": 12.1, "carbohydrates": 40.4, "dietaryFiber": 2},
    "×¢×•×’×ª ×ª×¤×•×—×™×": {"proteins": 3, "fats": 13, "carbohydrates": 38, "dietaryFiber": 1.5},
    "×¦×œ×—×ª ××¨×§ ×¡×œ×¨×™": {"proteins": 1, "fats": 0.5, "carbohydrates": 4, "dietaryFiber": 1.5},
    "×§×•×˜×’'": {"proteins": 11, "fats": 4.3, "carbohydrates": 3.5, "dietaryFiber": 0},
    "×¨×™×‘×”": {"proteins": 0.3, "fats": 0.1, "carbohydrates": 65, "dietaryFiber": 0.5},
    "×¡×œ×˜ ×‘×™×¦×™×": {"proteins": 13, "fats": 10, "carbohydrates": 1, "dietaryFiber": 0},
    "×‘×™×¦×™×": {"proteins": 13, "fats": 10, "carbohydrates": 1, "dietaryFiber": 0},
    "×©×¢×•×¢×™×ª ×™×¨×•×§×”": {"proteins": 1.8, "fats": 0.1, "carbohydrates": 7, "dietaryFiber": 3.4},
    "×§×™× ×•××”": {"proteins": 4.4, "fats": 1.9, "carbohydrates": 21.3, "dietaryFiber": 2.8},
    "×¢×•×£": {"proteins": 26.5, "fats": 3.6, "carbohydrates": 0, "dietaryFiber": 0},
    "×¤×ª×™×ª×™×": {"proteins": 5, "fats": 1, "carbohydrates": 30, "dietaryFiber": 1.2},
    "×›×¨×•×‘×™×ª ××‘×•×©×œ×ª": {"proteins": 2, "fats": 0.3, "carbohydrates": 5, "dietaryFiber": 2.5},
    "×›×¨×•×‘×™×ª": {"proteins": 2, "fats": 0.3, "carbohydrates": 5, "dietaryFiber": 2.5},
    "×ª×¤×•\"×": {"proteins": 2, "fats": 0.1, "carbohydrates": 15, "dietaryFiber": 1.5},
    "×ª×¤×•×—×™ ××“××”": {"proteins": 2, "fats": 0.1, "carbohydrates": 15, "dietaryFiber": 1.5},
    "××¨×§ ×™×¨×§×•×ª": {"proteins": 1.5, "fats": 0.5, "carbohydrates": 8, "dietaryFiber": 2},
    "××¨×§ ××¤×•× ×”": {"proteins": 5, "fats": 1, "carbohydrates": 15, "dietaryFiber": 5},
}

# ×—×™×©×•×‘ ×¢×¨×›×™× ×ª×–×•× ×ª×™×™× ×œ××¨×•×—×•×ª ××•×¨×›×‘×•×ª
def calculate_complex_meal_nutrition(meal_name):
    # ×¢×¨×›×™× ×“×™×¤×•×œ×˜×™×‘×™×™×
    nutrition = {"proteins": 0, "fats": 0, "carbohydrates": 0, "dietaryFiber": 0}
    
    # ×‘×“×™×§×” ×× ×™×© ×”×ª×××” ××“×•×™×§×ª ×‘××¡×“ ×”× ×ª×•× ×™×
    if meal_name in nutrition_db:
        return nutrition_db[meal_name]
    
    # ×¤×™×¦×•×œ ×”××¨×•×—×” ×œ××¨×›×™×‘×™×
    components = []
    for food in nutrition_db.keys():
        if food in meal_name:
            components.append(food)
    
    # ×× ×œ× × ××¦××• ××¨×›×™×‘×™×, ×”×—×–×¨ ×¢×¨×›×™× ×“×™×¤×•×œ×˜×™×‘×™×™×
    if not components:
        return nutrition
    
    # ×—×™×©×•×‘ ×”×¢×¨×›×™× ×”×ª×–×•× ×ª×™×™× ×¢×œ ×™×“×™ ×¡×›×™××ª ×”××¨×›×™×‘×™×
    # ×¢×‘×•×¨ ××¨×•×—×•×ª ××•×¨×›×‘×•×ª, × ×ª××™× ××ª ×”×× ×•×ª
    for component in components:
        if "×—×¦×™" in meal_name and component == "×¤×™×ª×”":
            # ×—×¦×™ ×¤×™×ª×”
            for nutrient in nutrition:
                nutrition[nutrient] += nutrition_db[component][nutrient] * 0.5
        elif "×¨×‘×¢" in meal_name and component == "×¤×™×ª×”":
            # ×¨×‘×¢ ×¤×™×ª×”
            for nutrient in nutrition:
                nutrition[nutrient] += nutrition_db[component][nutrient] * 0.25
        elif "50 ×’×¨×" in meal_name and component == "×¢×•×£":
            # 50 ×’×¨× ×¢×•×£ (×‘×¢×¨×š ×—×¦×™ ×× ×”)
            for nutrient in nutrition:
                nutrition[nutrient] += nutrition_db[component][nutrient] * 0.5
        elif "×§×˜×Ÿ" in meal_name and component == "×©× ×™×¦×œ":
            # ×©× ×™×¦×œ ×§×˜×Ÿ
            for nutrient in nutrition:
                nutrition[nutrient] += nutrition_db[component][nutrient] * 0.7
        elif "×§×¢×¨×ª" in meal_name and component == "×§×•×¨× ×¤×œ×§×¡":
            # ×§×¢×¨×ª ×§×•×¨× ×¤×œ×§×¡
            for nutrient in nutrition:
                nutrition[nutrient] += nutrition_db[component][nutrient] * 0.6  # ×”×ª×××ª ×’×•×“×œ ×”×× ×”
        elif component in meal_name:
            # ××¨×›×™×‘ ×¨×’×™×œ
            for nutrient in nutrition:
                nutrition[nutrient] += nutrition_db[component][nutrient] * 0.8  # ×”×ª×××” ×§×˜× ×” ×¢×‘×•×¨ ××–×•× ×•×ª ××©×•×œ×‘×™×
    
    # ×¢×™×’×•×œ ×¢×¨×›×™× ×œ×¡×¤×¨×” ××—×ª ××—×¨×™ ×”× ×§×•×“×”
    for nutrient in nutrition:
        nutrition[nutrient] = round(nutrition[nutrient], 1)
    
    return nutrition

# ×¤×•× ×§×¦×™×•×ª ×¢×™×‘×•×“
translated_data_global = {}
original_full_json = {}

def translate_value(value, key=None):
    if key == "notes" and not value:
        return value
    if isinstance(value, str):
        if value in translation_cache:
            return translation_cache[value]
        hebrew_chars = any('\u0590' <= c <= '\u05FF' for c in value)
        if hebrew_chars:
            try:
                result = translator.translate(value, "English")
                translation_cache[value] = result.result
                return result.result
            except:
                return value
        return value
    elif isinstance(value, dict):
        return {k: translate_value(v, k) for k, v in value.items()}
    elif isinstance(value, list):
        return [translate_value(item) for item in value]
    else:
        return value

def extract_food_nutrition(food_name):
    # ×§×•×“× ×‘×“×•×§ ×”×ª×××” ××“×•×™×§×ª
    if food_name in nutrition_db:
        return nutrition_db[food_name]
    # ×”×©×ª××© ×‘××—×©×‘×•×Ÿ ××¨×•×—×•×ª ××•×¨×›×‘×•×ª
    return calculate_complex_meal_nutrition(food_name)

def upload_and_process(file_obj):
    global translated_data_global, original_full_json
    try:
        with open(file_obj.name, 'r', encoding='utf-8') as f:
            content = f.read()

        original_full_json = json.loads(content)
        
        # ×•×•×“× ×©×›×œ ×”××¤×ª×—×•×ª ×”× ×“×¨×©×™× ×§×™×™××™×, ×›×•×œ×œ ×©×“×” 'feelings'
        keys_to_check = ["nutritions", "activities", "medications", "symptoms", "medicines", "feelings"]
        for key in keys_to_check:
            if key not in original_full_json:
                original_full_json[key] = []
        
        # ××–×’ 'feelings' ×œ×ª×•×š 'symptoms' ×× ×¦×¨×™×š
        if "feelings" in original_full_json and isinstance(original_full_json["feelings"], list):
            # ×”×•×¡×£ ×›×œ ×ª×—×•×©×” ×œ×¡×™××¤×˜×•××™× ×‘××•×ª×• ××‘× ×”
            for feeling in original_full_json["feelings"]:
                if isinstance(feeling, dict):
                    # ×›×‘×¨ ×‘×¤×•×¨××˜ ×”× ×›×•×Ÿ
                    original_full_json["symptoms"].append(feeling)
                elif isinstance(feeling, list):
                    # ×¨×©×™××” ×©×œ ×ª×—×•×©×•×ª
                    original_full_json["symptoms"].extend(feeling)
        
        # ×”××¨ ×©×“×•×ª ×ª××¨×™×š ×œ×¤×•×¨××˜ ×¡×˜× ×“×¨×˜×™ ×× ×”× ×§×™×™××™×
        date_keys = ["nutritions", "activities", "medications", "symptoms", "medicines"]
        for key in date_keys:
            if key in original_full_json:
                for item in original_full_json[key]:
                    if "dateTaken" in item:
                        item["date"] = item["dateTaken"]
                    # ×•×•×“× ×©×ª××¨×™×›×™× ×‘×¤×•×¨××˜ ×¢×§×‘×™
                    if "date" in item:
                        try:
                            item["date"] = pd.to_datetime(item["date"]).isoformat()
                        except:
                            pass
        
        # ×•×•×“× ×©×ª×¨×•×¤×•×ª/××˜×•×¤×œ×•×ª ×¢×§×‘×™×•×ª
        if "medicines" in original_full_json and "medications" not in original_full_json:
            original_full_json["medications"] = original_full_json["medicines"]
        elif "medications" in original_full_json and "medicines" not in original_full_json:
            original_full_json["medicines"] = original_full_json["medications"]
        
        keys_to_update = ["nutritions", "activities", "medications", "symptoms", "medicines"]

        for key in keys_to_update:
            if key in original_full_json:
                section = original_full_json[key]
                if isinstance(section, list):
                    for item in section:
                        if isinstance(item, dict):
                            # ×¢×“×›×Ÿ ×¢×¨×›×™× ×ª×–×•× ×ª×™×™× ×¢×‘×•×¨ ×¤×¨×™×˜×™ ××–×•×Ÿ
                            if key == "nutritions" and "foodName" in item:
                                food_name = item["foodName"]
                                item["nutritionalValues"] = extract_food_nutrition(food_name)
                
                # ×ª×¨×’× ××ª ×”××§×˜×¢
                original_full_json[key] = translate_value(section)

        translated_data_global = original_full_json

        # ×©××•×¨ ××ª ×”× ×ª×•× ×™× ×”××¢×•×‘×“×™×
        output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.json').name
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(translated_data_global, f, ensure_ascii=False, indent=2)

        return output_path, "âœ… File processed successfully! All nutritional values have been updated and data has been fully translated."
    except Exception as e:
        return None, f"âŒ Error processing: {str(e)}"

# --- ×¢×–×¨: ×”×›× ×ª ×”×“××˜×” ×¤×¨×™×™× ---

def prepare_activity_and_mood_data(data, mood_field):
    if not data or "activities" not in data or "symptoms" not in data:
        return pd.DataFrame(), pd.DataFrame()

    activity_list = []
    for item in data.get("activities", []):
        if "date" in item:
            activity_list.append({
                "date": pd.to_datetime(item["date"]),
                "item": item
            })
    activity_df = pd.DataFrame(activity_list)

    mood_list = []
    for item in data.get("symptoms", []):
        if "date" in item and item.get("type") == mood_field and "severity" in item:
            mood_list.append({
                "date": pd.to_datetime(item["date"]),
                "value": item["severity"]
            })
    mood_df = pd.DataFrame(mood_list)

    return activity_df, mood_df

def prepare_medication_and_mood_data(data, mood_field):
    if not data or "medications" not in data or "symptoms" not in data:
        return pd.DataFrame(), pd.DataFrame()

    medication_list = []
    for item in data.get("medications", []):
        if "date" in item:
            medication_list.append({
                "date": pd.to_datetime(item["date"]),
                "item": item
            })
    medication_df = pd.DataFrame(medication_list)

    mood_list = []
    for item in data.get("symptoms", []):
        if "date" in item and item.get("type") == mood_field and "severity" in item:
            mood_list.append({
                "date": pd.to_datetime(item["date"]),
                "value": item["severity"]
            })
    mood_df = pd.DataFrame(mood_list)

    return medication_df, mood_df

def prepare_symptom_and_mood_data(data, mood_field):
    if not data or "symptoms" not in data:
        return pd.DataFrame(), pd.DataFrame()

    symptom_list = []
    for item in data.get("symptoms", []):
        if "date" in item:
            symptom_list.append({
                "date": pd.to_datetime(item["date"]),
                "item": item
            })
    symptom_df = pd.DataFrame(symptom_list)

    mood_list = []
    for item in data.get("symptoms", []):
        if "date" in item and item.get("type") == mood_field and "severity" in item:
            mood_list.append({
                "date": pd.to_datetime(item["date"]),
                "value": item["severity"]
            })
    mood_df = pd.DataFrame(mood_list)

    return symptom_df, mood_df

# ×¤×•× ×§×¦×™×•×ª ×™×¦×™×¨×ª ×ª×•×‘× ×•×ª ×‘×¡×™×¡×™×•×ª
def generate_activity_insights(activity_df, mood_df):
    insights = "ğŸƒ Activity Insights:\n"

    if activity_df.empty or mood_df.empty:
        return insights + "Not enough data to analyze activities and mood correlation.\n"

    combined_data = []
    for _, mood_row in mood_df.iterrows():
        mood_date = mood_row["date"]
        mood_value = mood_row["value"]
        same_day_activities = activity_df[activity_df["date"].dt.date == mood_date.date()]
        for _, act_row in same_day_activities.iterrows():
            activity_item = act_row["item"]
            time_diff = 24
            if "startTime" in activity_item:
                try:
                    act_time = pd.to_datetime(activity_item["startTime"])
                    time_diff = abs((mood_date - act_time).total_seconds() / 3600)
                except:
                    pass
            if time_diff <= 6:
                activity_type = activity_item.get("activityName", "Unknown")
                duration = activity_item.get("duration", 0)
                intensity = activity_item.get("intensity", 0)
                combined_data.append({
                    "mood_value": mood_value,
                    "activity_type": activity_type,
                    "duration": duration,
                    "intensity": intensity,
                    "time_diff": time_diff
                })

    if not combined_data or len(combined_data) < 2:
        return insights + "Not enough close-timing data.\n"

    analysis_df = pd.DataFrame(combined_data)
    insights += "â€¢ Activity type impact on mood:\n"
    activity_types = analysis_df["activity_type"].unique()
    for activity in activity_types:
        act_mood = analysis_df[analysis_df["activity_type"] == activity]["mood_value"].mean()
        overall_mood = mood_df["value"].mean()
        diff = act_mood - overall_mood
        if not np.isnan(act_mood):
            count = len(analysis_df[analysis_df["activity_type"] == activity])
            direction = "higher" if diff > 0 else "lower"
            if abs(diff) >= 0.5:
                insights += f"  - {activity} ({count} times): Mood tends to be {abs(round(diff, 1))} points {direction} than average.\n"
            else:
                insights += f"  - {activity} ({count} times): Mood similar to average.\n"

    return insights

def generate_medication_insights(medication_df, mood_df):
    insights = "ğŸ’Š Medication Insights:\n"

    if medication_df.empty or mood_df.empty:
        return insights + "Not enough data to analyze medications.\n"

    combined_data = []
    for _, mood_row in mood_df.iterrows():
        mood_date = mood_row["date"]
        mood_value = mood_row["value"]
        same_day_meds = medication_df[medication_df["date"].dt.date == mood_date.date()]
        for _, med_row in same_day_meds.iterrows():
            med_item = med_row["item"]
            time_diff = 24
            if "timeTaken" in med_item:
                try:
                    med_time = pd.to_datetime(med_item["timeTaken"])
                    time_diff = abs((mood_date - med_time).total_seconds() / 3600)
                except:
                    pass
            if time_diff <= 6:
                med_name = med_item.get("name", "Unknown")
                dosage = med_item.get("quantity", 0)
                combined_data.append({
                    "mood_value": mood_value,
                    "medication": med_name,
                    "dosage": dosage,
                    "time_diff": time_diff
                })

    if not combined_data or len(combined_data) < 2:
        return insights + "Not enough close-timing data.\n"

    analysis_df = pd.DataFrame(combined_data)
    insights += "â€¢ Medication impact on mood:\n"
    medications = analysis_df["medication"].unique()
    for med in medications:
        med_mood = analysis_df[analysis_df["medication"] == med]["mood_value"].mean()
        overall_mood = mood_df["value"].mean()
        diff = med_mood - overall_mood
        if not np.isnan(med_mood):
            count = len(analysis_df[analysis_df["medication"] == med])
            direction = "higher" if diff > 0 else "lower"
            if abs(diff) >= 0.3:
                insights += f"  - {med} ({count} times): Mood tends to be {abs(round(diff, 1))} points {direction}.\n"
            else:
                insights += f"  - {med} ({count} times): Mood similar to average.\n"

    return insights

def generate_symptom_insights(symptom_df, mood_df):
    insights = "ğŸ©º Symptom Insights:\n"

    if symptom_df.empty or mood_df.empty:
        return insights + "Not enough data to analyze symptoms.\n"

    symptom_fields = set()
    for _, row in symptom_df.iterrows():
        item = row["item"]
        for key in item.keys():
            if key not in ["date", "notes", "id", "Parkinson's State", "My Mood", "Physical State", "type", "severity", "createdAt", "updatedAt", "__v", "_id", "userId"]:
                symptom_fields.add(key)
    symptom_fields = list(symptom_fields)

    # ×”×•×¡×£ ×’× ××ª ×”×¡×™××¤×˜×•××™× ×©××•×¤×™×¢×™× ×‘×©×“×” type
    for _, row in symptom_df.iterrows():
        item = row["item"]
        if "type" in item and item["type"] not in ["Parkinson's State", "My Mood", "Physical State"]:
            symptom_fields.append(item["type"])
    
    # ×”×¡×¨ ×›×¤×™×œ×•×™×•×ª
    symptom_fields = list(set(symptom_fields))

    if not symptom_fields:
        return insights + "No specific symptom fields detected.\n"

    insights += "â€¢ Symptom impact on mood:\n"
    date_to_mood = {row["date"].date(): row["value"] for _, row in mood_df.iterrows()}

    for symptom in symptom_fields:
        symptom_present_moods = []
        symptom_absent_moods = []
        for _, row in symptom_df.iterrows():
            date = row["date"].date()
            item = row["item"]
            if date in date_to_mood:
                mood_value = date_to_mood[date]
                symptom_present = False
                # ×‘×“×•×§ ×× ×”×¡×™××¤×˜×•× ××•×¤×™×¢ ×›×©×“×”
                if symptom in item and item[symptom]:
                    symptom_present = True
                # ×‘×“×•×§ ×× ×”×¡×™××¤×˜×•× ××•×¤×™×¢ ×›×¢×¨×š ×‘×©×“×” type
                if "type" in item and item["type"] == symptom:
                    symptom_present = True
                
                if symptom_present:
                    symptom_present_moods.append(mood_value)
                else:
                    symptom_absent_moods.append(mood_value)
                    
        if symptom_present_moods and symptom_absent_moods:
            present_avg = np.mean(symptom_present_moods)
            absent_avg = np.mean(symptom_absent_moods)
            diff = present_avg - absent_avg
            direction = "higher" if diff > 0 else "lower"
            if abs(diff) >= 0.3:
                insights += f"  - {symptom}: Mood {direction} by {round(abs(diff),1)} points when present.\n"
            else:
                insights += f"  - {symptom}: No strong mood impact.\n"

    return insights

# ×¤×•× ×§×¦×™×•×ª × ×™×ª×•×— ××ª×§×“××•×ª
def analyze_activity_patterns(data, mood_field):
    if not data or "activities" not in data or "symptoms" not in data:
        return "Not enough data for activity pattern analysis."
    
    try:
        # ×—×™×œ×•×¥ × ×ª×•× ×™ ×¤×¢×™×œ×•×ª
        activity_data = []
        for item in data.get("activities", []):
            if "date" in item and "activityName" in item and "duration" in item and "intensity" in item:
                # ×•×•×“× ×©×”×©× ×”××“×•×™×§ ×©×œ ×”×¤×¢×™×œ×•×ª × ×œ×§×— ××”×©×“×” ×”× ×›×•×Ÿ
                activity_name = item.get("activityName", "")
                if not activity_name or len(activity_name) < 2:
                    continue  # ×“×œ×’ ×¢×œ ×¤×¢×™×œ×•×™×•×ª ×œ×œ× ×©× ×ª×§×™×Ÿ
                
                activity_data.append({
                    "date": pd.to_datetime(item["date"]),
                    "name": activity_name,
                    "duration": item.get("duration", 0),
                    "intensity": item.get("intensity", "Low"),
                    "notes": item.get("notes", "")
                })
        
        # ×§×‘×œ × ×ª×•× ×™ ××¦×‘ ×¨×•×—/×¡×™××¤×˜×•×
        mood_data = []
        for item in data["symptoms"]:
            if "date" in item and "type" in item and item.get("type") == mood_field and "severity" in item:
                mood_data.append({
                    "date": pd.to_datetime(item["date"]),
                    "severity": item.get("severity", 0)
                })
        
        if len(activity_data) < 3 or len(mood_data) < 3:
            return "Not enough data points for activity analysis."
        
        # ×¦×•×¨ DataFrames
        activity_df = pd.DataFrame(activity_data)
        mood_df = pd.DataFrame(mood_data)
        
        # ×”××¨ ×¢×•×¦××” ×œ××¡×¤×¨×™
        intensity_map = {"Low": 1, "Moderate": 2, "High": 3}
        activity_df["intensity_score"] = activity_df["intensity"].map(lambda x: intensity_map.get(x, 1))
        
        # ×—×©×‘ ×¦×™×•×Ÿ ×¤×¢×™×œ×•×ª (××©×š * ×¢×•×¦××”)
        activity_df["activity_score"] = activity_df["duration"] * activity_df["intensity_score"]
        
        # ×”×ª×× ×¤×¢×™×œ×•×™×•×ª ×¢× ××¦×‘ ×¨×•×— (×ª×•×š 6 ×©×¢×•×ª)
        matched_data = []
        
        for _, act_row in activity_df.iterrows():
            act_date = act_row["date"]
            
            # ××¦× ××“×™×“×•×ª ××¦×‘ ×¨×•×— ××—×¨×™ ×”×¤×¢×™×œ×•×ª (×ª×•×š 6 ×©×¢×•×ª)
            relevant_moods = mood_df[(mood_df["date"] >= act_date) & 
                                    (mood_df["date"] <= act_date + pd.Timedelta(hours=6))]
            
            if not relevant_moods.empty:
                # ×§×— ××ª ×××•×¦×¢ ××¦×‘ ×”×¨×•×— ×× ×™×©× × ××¡×¤×¨ ×¨×©×•××•×ª
                avg_mood = relevant_moods["severity"].mean()
                
                matched_data.append({
                    "date": act_date,
                    "activity_name": act_row["name"],
                    "duration": act_row["duration"],
                    "intensity_score": act_row["intensity_score"],
                    "activity_score": act_row["activity_score"],
                    "mood_after": avg_mood
                })
        
        if len(matched_data) < 3:
            return "Not enough matched activity-mood data for analysis."
        
        matched_df = pd.DataFrame(matched_data)
        
        # ×§×‘×¥ ×œ×¤×™ ×©× ×¤×¢×™×œ×•×ª
        activity_analysis = []
        
        for activity_name, group in matched_df.groupby("activity_name"):
            if len(group) >= 2:  # ×œ×¤×—×•×ª 2 ××•×¤×¢×™×
                # ×‘×“×•×§ ×©× ×¤×¢×™×œ×•×ª ×ª×§×™×Ÿ
                if not activity_name or len(activity_name) < 2:
                    continue
                
                avg_duration = group["duration"].mean()
                avg_score = group["activity_score"].mean()
                avg_mood = group["mood_after"].mean()
                
                # ××ª×× ×‘×™×Ÿ ×¦×™×•×Ÿ ×¤×¢×™×œ×•×ª ×•××¦×‘ ×¨×•×— (×× ×™×© ××¡×¤×™×§ × ×§×•×“×•×ª × ×ª×•× ×™×)
                correlation = None
                if len(group) >= 3:
                    if group["activity_score"].std() > 0 and group["mood_after"].std() > 0:
                        correlation, p_value = pearsonr(group["activity_score"], group["mood_after"])
                        # ×× ×”×§×•×¨×œ×¦×™×” ×œ× ××•×‘×”×§×ª (p-value ×’×‘×•×”), ××œ ×ª×¦×™×’ ××•×ª×”
                        if p_value > 0.2:
                            correlation = None
                
                activity_analysis.append({
                    "activity_name": activity_name,
                    "count": len(group),
                    "avg_duration": round(avg_duration, 1),
                    "avg_mood_after": round(avg_mood, 2),
                    "correlation": round(correlation, 3) if correlation is not None else None
                })
        
        # ××™×™×Ÿ ×œ×¤×™ ×”×©×¤×¢×ª ××¦×‘ ×¨×•×— (×”×’×‘×•×” ×‘×™×•×ª×¨ ×ª×—×™×œ×”)
        activity_analysis.sort(key=lambda x: x["avg_mood_after"], reverse=True)
        
        return activity_analysis
    except Exception as e:
        return f"Error in activity pattern analysis: {str(e)}"

def analyze_medication_patterns(data, mood_field):
    if not data or "medications" not in data or "symptoms" not in data:
        return "Not enough data for medication pattern analysis."
    
    try:
        # ×—×™×œ×•×¥ × ×ª×•× ×™ ×ª×¨×•×¤×•×ª
        med_data = []
        for item in data.get("medications", []):
            if "date" in item and "name" in item:
                med_data.append({
                    "date": pd.to_datetime(item["date"]),
                    "name": item["name"],
                    "quantity": item.get("quantity", 1)
                })
        
        # ×§×‘×œ × ×ª×•× ×™ ××¦×‘ ×¨×•×—/×¡×™××¤×˜×•×
        mood_data = []
        for item in data["symptoms"]:
            if "date" in item and "type" in item and item.get("type") == mood_field and "severity" in item:
                mood_data.append({
                    "date": pd.to_datetime(item["date"]),
                    "severity": item.get("severity", 0)
                })
        
        if len(med_data) < 5 or len(mood_data) < 5:
            return "Not enough data points for medication analysis."
        
        # ×¦×•×¨ DataFrames
        med_df = pd.DataFrame(med_data)
        mood_df = pd.DataFrame(mood_data)
        
        # ×§×‘×¥ ×œ×¤×™ ×™×•× ×œ×™×¦×™×¨×ª ×˜×¨× ×–×§×¦×™×•×ª
        med_df["day"] = med_df["date"].dt.date
        mood_df["day"] = mood_df["date"].dt.date
        
        # ×¦×•×¨ ×¡×˜ × ×ª×•× ×™ ×˜×¨× ×–×§×¦×™×•×ª
        days = sorted(set(list(med_df["day"]) + list(mood_df["day"])))
        transactions = []
        
        for day in days:
            day_meds = med_df[med_df["day"] == day]["name"].unique().tolist()
            
            # ×¢×‘×•×¨ ××¦×‘ ×¨×•×—, ×§×‘×œ ××ª ×”×××•×¦×¢ ×©×œ ××•×ª×• ×™×•×
            day_mood_df = mood_df[(mood_df["day"] == day) & (mood_df["type"] == mood_field)]
            
            if not day_mood_df.empty:
                avg_severity = day_mood_df["severity"].mean()
                mood_level = f"{mood_field}_Level_{round(avg_severity)}"
                transaction = day_meds + [mood_level]
                transactions.append(transaction)
        
        if len(transactions) < 5:
            return "Not enough daily data for pattern analysis."
        
        # ×”×¤×¢×œ ××œ×’×•×¨×™×ª× Apriori ×¢×‘×•×¨ ×¡×˜×™× ×ª×“×™×¨×™×
        te = TransactionEncoder()
        te_ary = te.fit(transactions).transform(transactions)
        df = pd.DataFrame(te_ary, columns=te.columns_)
        
        # ××¦× ×¡×˜×™× ×ª×“×™×¨×™×
        frequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)
        
        if frequent_itemsets.empty:
            return "No significant patterns found with current support threshold."
        
        # ×¦×•×¨ ×—×•×§×™ ××¡×•×¦×™××¦×™×”
        rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.5)
        
        if rules.empty:
            return "No strong association rules found."
        
        # ×¡× ×Ÿ ×—×•×§×™× ×”×§×©×•×¨×™× ×œ×¨××•×ª ××¦×‘ ×¨×•×—
        mood_rules = []
        for _, rule in rules.iterrows():
            antecedents = list(rule["antecedents"])
            # ×‘×“×™×§×” ×× ×× ×˜×™×¦×“× ×˜ ××• ×§×•× ×¡×§×•×•× ×˜ ××›×™×œ×™× ×“×™×¨×•×’×™ ×¨××ª ××¦×‘ ×¨×•×—
            mood_level_pattern = f"{mood_field}_Level_"
            has_mood = False
            
            for item in list(rule["antecedents"]) + list(rule["consequents"]):
                if isinstance(item, str) and item.startswith(mood_level_pattern):
                    has_mood = True
                    break
            
            if has_mood:
                rule_dict = {
                    "antecedents": list(rule["antecedents"]),
                    "consequents": list(rule["consequents"]),
                    "confidence": rule["confidence"],
                    "lift": rule["lift"]
                }
                mood_rules.append(rule_dict)
        
        if len(mood_rules) == 0:
            return "No significant medication-mood associations found."
            
        # ××™×•×Ÿ ×œ×¤×™ lift (×—×©×™×‘×•×ª)
        mood_rules.sort(key=lambda x: x["lift"], reverse=True)
        
        return mood_rules[:5]  # ×”×—×–×¨ 5 ×—×•×§×™× ×¢×œ×™×•× ×™×
    except Exception as e:
        return f"Error in medication pattern analysis: {str(e)}"

# ×¤×•× ×§×¦×™×•×ª × ×™×ª×•×— ×¢×‘×•×¨ ×××©×§ ×”××©×ª××©
def activity_analysis_summary(mood_field):
    if not translated_data_global:
        return "Please upload and process data first."
        
    # × ×ª×— ××ª ×”×¤×¢×™×œ×•×™×•×ª ×‘×¦×•×¨×” ×‘×¡×™×¡×™×ª (×œ×¤×™ ×”×××©×§ ×”×¤×©×•×˜)
    activity_df, mood_df = prepare_activity_and_mood_data(translated_data_global, mood_field)
    basic_insights = generate_activity_insights(activity_df, mood_df)
    
    # ×× ××™×Ÿ ××¡×¤×™×§ × ×ª×•× ×™×, ×”×—×–×¨ ××ª ×”× ×™×ª×•×— ×”×‘×¡×™×¡×™
    if "Not enough data" in basic_insights or "Not enough close-timing data" in basic_insights:
        return basic_insights
    
    # × ×ª×— ××ª ×”×¤×¢×™×œ×•×™×•×ª ×‘×¦×•×¨×” ××ª×§×“××ª
    advanced_analysis = analyze_activity_patterns(translated_data_global, mood_field)
    
    # ×× ×™×© ×©×’×™××” ××• ××™×Ÿ ××¡×¤×™×§ × ×ª×•× ×™×, ×”×—×–×¨ ×¨×§ ××ª ×”× ×™×ª×•×— ×”×‘×¡×™×¡×™
    if isinstance(advanced_analysis, str):
        if "Not enough" in advanced_analysis:
            return basic_insights
        return basic_insights + "\n\n" + advanced_analysis
    
    # ×× ××™×Ÿ ×¤×¢×™×œ×•×™×•×ª ×œ× ×™×ª×•×—, ×”×—×–×¨ ×¨×§ ××ª ×”× ×™×ª×•×— ×”×‘×¡×™×¡×™
    if not advanced_analysis:
        return basic_insights
    
    # ×‘× ×” ×ª×•×‘× ×•×ª ××¤×•×¨×˜×•×ª ×¢×œ ×¡××š ×”× ×™×ª×•×— ×”××ª×§×“×
    detailed_insights = "\n\nDetailed Activity Analysis:\n"
    for activity in advanced_analysis[:3]:
        # ×•×•×“× ×©×™×© ×©× ×¤×¢×™×œ×•×ª ×ª×§×™×Ÿ
        activity_name = activity.get('activity_name', '')
        if not activity_name or len(activity_name) < 2 or activity_name == "Unknown":
            continue
            
        # ×•×•×“× ×©×™×© ×œ×¤×—×•×ª 2 ××•×¤×¢×™× ×©×œ ×”×¤×¢×™×œ×•×ª
        if activity.get('count', 0) < 2:
            continue
            
        detailed_insights += f"- {activity_name}: {activity.get('avg_mood_after', 0):.1f}/5 rating after {activity.get('count')} activities\n"
        
        # ×¨×§ ×× ×™×© ×§×•×¨×œ×¦×™×” ××©××¢×•×ª×™×ª ×•×’× ×œ×¤×—×•×ª 3 ××•×¤×¢×™×, ×”×¦×’ ××•×ª×”
        if activity.get('correlation') is not None and abs(activity.get('correlation', 0)) > 0.3 and activity.get('count', 0) >= 3:
            corr = activity.get('correlation')
            direction = "positive" if corr > 0 else "negative"
            explanation = "higher intensity = better mood" if corr > 0 else "lower intensity = better mood"
            detailed_insights += f"  ({explanation}, correlation: {corr:.2f})\n"
    
    # ×¨×§ ×× × ×•×¡×¤×• ×ª×•×‘× ×•×ª ××¤×•×¨×˜×•×ª ××¢×‘×¨ ×œ×›×•×ª×¨×ª, ×”×—×–×¨ ××•×ª×Ÿ
    if detailed_insights != "\n\nDetailed Activity Analysis:\n":
        return basic_insights + detailed_insights
    else:
        return basic_insights

def medication_analysis_summary(mood_field):
    if not translated_data_global:
        return "Please upload and process data first."
    medication_df, mood_df = prepare_medication_and_mood_data(translated_data_global, mood_field)
    basic_insights = generate_medication_insights(medication_df, mood_df)
    
    # ×©×œ×‘ ××ª ×”×ª×•×‘× ×•×ª ×”×‘×¡×™×¡×™×•×ª ×¢× ×”× ×™×ª×•×— ×”××ª×§×“×
    advanced_analysis = analyze_medication_patterns(translated_data_global, mood_field)
    
    if isinstance(advanced_analysis, str):
        if "Not enough" in advanced_analysis or "No significant" in advanced_analysis:
            return basic_insights
        return basic_insights + "\n\n" + advanced_analysis
    
    detailed_insights = "\n\nDetailed Medication Patterns:\n"
    for idx, rule in enumerate(advanced_analysis[:3]):
        antecedents = list(rule.get("antecedents", []))
        consequents = list(rule.get("consequents", []))
        
        meds = []
        mood_level = None
        
        for item in antecedents + consequents:
            if isinstance(item, str):
                if item.startswith(f"{mood_field}_Level_"):
                    mood_level = item.replace(f"{mood_field}_Level_", "Rating: ")
                else:
                    meds.append(item)
        
        if meds and mood_level:
            meds_str = ", ".join(meds)
            detailed_insights += f"- {meds_str} associated with {mood_level}\n"
            detailed_insights += f"  (Confidence: {rule.get('confidence', 0):.2f}, Lift: {rule.get('lift', 0):.2f})\n"
    
    if detailed_insights != "\n\nDetailed Medication Patterns:\n":
        return basic_insights + detailed_insights
    else:
        return basic_insights

def symptom_analysis_summary(mood_field):
    if not translated_data_global:
        return "Please upload and process data first."
    symptom_df, mood_df = prepare_symptom_and_mood_data(translated_data_global, mood_field)
    return generate_symptom_insights(symptom_df, mood_df)

# ×¤×•× ×§×¦×™×•×ª ×¢×™×‘×•×“ ×§×•×‘×¥
def upload_json(file_obj):
    global translated_data_global
    if file_obj is None:
        return None, "âŒ No file uploaded."
    try:
        # × ×©×ª××© ×‘×¤×•× ×§×¦×™×” ×”××§×•×¨×™×ª ×©×›×•×œ×œ×ª ×ª×¨×’×•× ×•× ×™×ª×•×— ×ª×–×•× ×ª×™
        processed_file, status = upload_and_process(file_obj)
        return processed_file, status
    except Exception as e:
        return None, f"âŒ Error: {str(e)}"

# ×™×¦×™×¨×ª ×”××¤×œ×™×§×¦×™×” ×¢× ×”×¢×™×¦×•×‘ ×”×—×“×©
with gr.Blocks(title="Parkinson's Health Pattern Analysis") as app:
    gr.Markdown("# ğŸ“ˆ Parkinson's Health Pattern Analysis")

    with gr.Row():
        file_input = gr.File(label="Upload JSON File")
        upload_button = gr.Button("Upload and Process", variant="primary", size="lg")
    
    output_text = gr.Textbox(label="Status", interactive=False)
    processed_file = gr.File(label="Download Processed File", interactive=False)

    mood_selector = gr.Dropdown(
        ["Parkinson's State", "Physical State", "My Mood"],
        label="Select Mood Field",
        value="My Mood"
    )

    with gr.Tabs():
        with gr.TabItem("ğŸƒ Activity Analysis"):
            activity_button = gr.Button("Analyze Activity Patterns", variant="primary")
            activity_output = gr.Markdown(label="Activity Insights")
        
        with gr.TabItem("ğŸ’Š Medication Analysis"):
            medication_button = gr.Button("Analyze Medication Patterns", variant="primary")
            medication_output = gr.Markdown(label="Medication Insights")

        with gr.TabItem("ğŸ©º Symptom Analysis"):
            symptom_button = gr.Button("Analyze Symptom Patterns", variant="primary")
            symptom_output = gr.Markdown(label="Symptom Insights")

    # ×§×™×©×•×¨ ×”×¤×•× ×§×¦×™×•×ª ×œ×›×¤×ª×•×¨×™×
    upload_button.click(fn=upload_json, inputs=[file_input], outputs=[processed_file, output_text])
    activity_button.click(fn=activity_analysis_summary, inputs=[mood_selector], outputs=[activity_output])
    medication_button.click(fn=medication_analysis_summary, inputs=[mood_selector], outputs=[medication_output])
    symptom_button.click(fn=symptom_analysis_summary, inputs=[mood_selector], outputs=[symptom_output])

# ×”×¤×¢×œ×ª ×”××¤×œ×™×§×¦×™×”
if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    app.launch(server_name='0.0.0.0', server_port=port)
